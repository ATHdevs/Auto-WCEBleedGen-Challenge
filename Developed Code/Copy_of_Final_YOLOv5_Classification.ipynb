{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary functionality from the google.colab module.\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive to a specified directory within the Colab environment.\n",
        "# This will prompt you to authenticate and grant access to your Google Drive account.\n",
        "# After mounting, your Google Drive contents will be accessible in Colab.\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pRXklW7YXMF",
        "outputId": "a7be0243-01fd-4ead-a2de-f0dd4b9a7d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Pull in respective libraries to prepare the notebook environment."
      ],
      "metadata": {
        "id": "-PJ8vlYXbWtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIM7fOwm8A7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5bd7d3-1448-40e4-bea0-ccabf2effd5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.5/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Clone the YOLOv5 repository from the specified GitHub URL.\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "\n",
        "# Change the current working directory to the 'yolov5' directory.\n",
        "%cd yolov5\n",
        "\n",
        "# Install the required Python packages listed in the 'requirements.txt' file.\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "# Import the PyTorch library.\n",
        "import torch\n",
        "\n",
        "# Import utility functions from the 'utils' module.\n",
        "import utils\n",
        "\n",
        "# Initialize the display using the 'notebook_init' function from 'utils'.\n",
        "# This function checks the notebook environment and sets up the necessary display settings.\n",
        "display = utils.notebook_init()  # checks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the current working directory to the parent directory of 'yolov5'.\n",
        "%cd ../yolov5\n",
        "\n",
        "# Run the 'train.py' script using Python to start the training process.\n",
        "# Arguments:\n",
        "#   --model yolov5s-cls.pt: Specifies the model checkpoint file to use for training.\n",
        "#   --data /content/drive/MyDrive/train_v5/images: Specifies the data directory for training.\n",
        "#   --epochs 100: Specifies the number of training epochs (in this case, 100 epochs).\n",
        "#   --img 128: Specifies the input image size (in this case, 128x128 pixels).\n",
        "#   --pretrained weights/yolov5s-cls.pt: Specifies a pre-trained model checkpoint to initialize the training.\n",
        "!python classify/train.py --model yolov5x-cls.pt --data /content/drive/MyDrive/datasetv1/images --epochs 100 --img 128 --pretrained weights/yolov5x-cls.pt\n"
      ],
      "metadata": {
        "id": "MXWTTN2BEaqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda5589e-3436-4371-b875-9a748acfb611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5x-cls.pt, data=/content/drive/MyDrive/datasetv1/images, epochs=100, batch_size=64, imgsz=128, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=weights/yolov5x-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=128, width=128, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x-cls.pt to yolov5x-cls.pt...\n",
            "100% 92.0M/92.0M [00:01<00:00, 80.9MB/s]\n",
            "\n",
            "Model summary: 338 layers, 46818722 parameters, 46818722 gradients, 129.5 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 74 weight(decay=0.0), 75 weight(decay=5e-05), 75 bias\n",
            "Image sizes 128 train, 128 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp3\u001b[0m\n",
            "Starting yolov5x-cls.pt training on /content/drive/MyDrive/datasetv1/images dataset with 2 classes for 100 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n",
            "     1/100     2.52G        0.76       0.696         0.5           1: 100% 29/29 [00:11<00:00,  2.43it/s]\n",
            "     2/100     2.52G       0.618        10.9         0.5           1: 100% 29/29 [00:11<00:00,  2.60it/s]\n",
            "     3/100     2.52G       0.468        1.01       0.534           1: 100% 29/29 [00:09<00:00,  2.96it/s]\n",
            "     4/100     2.52G       0.424        1.72       0.284           1: 100% 29/29 [00:10<00:00,  2.70it/s]\n",
            "     5/100     2.52G       0.434       0.889       0.277           1: 100% 29/29 [00:10<00:00,  2.64it/s]\n",
            "     6/100     2.52G       0.413       0.814       0.682           1: 100% 29/29 [00:11<00:00,  2.50it/s]\n",
            "     7/100     2.52G       0.423        1.34        0.39           1: 100% 29/29 [00:11<00:00,  2.61it/s]\n",
            "     8/100     2.52G       0.423       0.996       0.371           1: 100% 29/29 [00:10<00:00,  2.75it/s]\n",
            "     9/100     2.52G       0.399        1.14       0.337           1: 100% 29/29 [00:11<00:00,  2.61it/s]\n",
            "    10/100     2.52G       0.416         1.1       0.364           1: 100% 29/29 [00:11<00:00,  2.53it/s]\n",
            "    11/100     2.52G       0.407       0.768       0.333           1: 100% 29/29 [00:11<00:00,  2.49it/s]\n",
            "    12/100     2.52G       0.401       0.718       0.341           1: 100% 29/29 [00:11<00:00,  2.53it/s]\n",
            "    13/100     2.52G       0.401        0.93       0.367           1: 100% 29/29 [00:10<00:00,  2.67it/s]\n",
            "    14/100     2.52G       0.398        1.09       0.314           1: 100% 29/29 [00:10<00:00,  2.71it/s]\n",
            "    15/100     2.52G       0.397       0.944       0.333           1: 100% 29/29 [00:11<00:00,  2.54it/s]\n",
            "    16/100     2.52G       0.393        1.14       0.314           1: 100% 29/29 [00:11<00:00,  2.52it/s]\n",
            "    17/100     2.52G       0.398       0.857       0.333           1: 100% 29/29 [00:11<00:00,  2.53it/s]\n",
            "    18/100     2.52G       0.394        1.68       0.371           1: 100% 29/29 [00:10<00:00,  2.74it/s]\n",
            "    19/100     2.52G       0.391        0.91       0.352           1: 100% 29/29 [00:10<00:00,  2.80it/s]\n",
            "    20/100     2.52G       0.391       0.937       0.345           1: 100% 29/29 [00:11<00:00,  2.58it/s]\n",
            "    21/100     2.52G       0.389       0.698       0.345           1: 100% 29/29 [00:11<00:00,  2.56it/s]\n",
            "    22/100     2.52G       0.372        3.48       0.345           1: 100% 29/29 [00:11<00:00,  2.56it/s]\n",
            "    23/100     2.52G        0.39        1.27       0.341           1: 100% 29/29 [00:11<00:00,  2.58it/s]\n",
            "    24/100     2.52G       0.386        1.19       0.337           1: 100% 29/29 [00:10<00:00,  2.84it/s]\n",
            "    25/100     2.52G       0.388        1.21       0.348           1: 100% 29/29 [00:11<00:00,  2.51it/s]\n",
            "    26/100     2.52G       0.403        1.62       0.341           1: 100% 29/29 [00:11<00:00,  2.54it/s]\n",
            "    27/100     2.52G       0.373        1.06       0.341           1: 100% 29/29 [00:11<00:00,  2.56it/s]\n",
            "    28/100     2.52G       0.374        0.96       0.314           1: 100% 29/29 [00:11<00:00,  2.51it/s]\n",
            "    29/100     2.52G       0.386       0.722       0.402           1: 100% 29/29 [00:10<00:00,  2.81it/s]\n",
            "    30/100     2.52G       0.386        1.64       0.473           1: 100% 29/29 [00:10<00:00,  2.68it/s]\n",
            "    31/100     2.52G       0.372       0.737       0.394           1: 100% 29/29 [00:11<00:00,  2.49it/s]\n",
            "    32/100     2.52G       0.368       0.947       0.345           1: 100% 29/29 [00:11<00:00,  2.61it/s]\n",
            "    33/100     2.52G       0.386        0.95       0.402           1: 100% 29/29 [00:11<00:00,  2.46it/s]\n",
            "    34/100     2.52G       0.386       0.718       0.504           1: 100% 29/29 [00:10<00:00,  2.77it/s]\n",
            "    35/100     2.52G       0.395         2.7       0.394           1: 100% 29/29 [00:10<00:00,  2.72it/s]\n",
            "    36/100     2.52G       0.366        1.34       0.333           1: 100% 29/29 [00:11<00:00,  2.58it/s]\n",
            "    37/100     2.52G       0.383        2.46       0.364           1: 100% 29/29 [00:11<00:00,  2.60it/s]\n",
            "    38/100     2.52G       0.379        1.83       0.614           1: 100% 29/29 [00:11<00:00,  2.59it/s]\n",
            "    39/100     2.52G       0.375       0.783       0.587           1: 100% 29/29 [00:10<00:00,  2.81it/s]\n",
            "    40/100     2.52G       0.375                                    :  62% 18/29 [00:07<00:03,  2.97it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate Your Custom Model\n",
        "\n",
        "Repeat step 2 from above to test and validate your custom model."
      ],
      "metadata": {
        "id": "HHUFGeLbGd98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data /content/drive/MyDrive/datasetv1/images"
      ],
      "metadata": {
        "id": "DIV7ydyKGZFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f7055d-3664-4eaa-ee18-dd17fdc8961d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/content/drive/MyDrive/datasetv1/images, weights=['runs/train-cls/exp/weights/best.pt'], batch_size=128, imgsz=224, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 4169250 parameters, 0 gradients, 10.4 GFLOPs\n",
            "testing: 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "                   Class      Images    top1_acc    top5_acc\n",
            "                     all         264       0.727           1\n",
            "                bleeding         132       0.455           1\n",
            "            non_bleeding         132           1           1\n",
            "Speed: 0.1ms pre-process, 4.4ms inference, 0.2ms post-process per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/val-cls/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights yolov5x-cls.pt --source '/content/A0000.png'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVGmFW9zJHrH",
        "outputId": "1935b2b6-f4ac-4d62-ea90-50fb52699f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['yolov5s-cls.pt'], source=/content/A0000.png, data=data/custom_data.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-226-gdd9e338 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 5447688 parameters, 0 gradients, 11.4 GFLOPs\n",
            "image 1/1 /content/A0000.png: 224x224 pot pie 0.09, dough 0.06, mashed potato 0.04, steel drum 0.03, gyromitra 0.03, 4.9ms\n",
            "Speed: 0.4ms pre-process, 4.9ms inference, 6.6ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (BONUS) YOLOv5 classify/predict.py Accepts Several Input Methods\n",
        "- Webcam: `python classify/predict.py --weights yolov5s-cls.pt --source 0`\n",
        "- Image `python classify/predict.py --weights yolov5s-cls.pt --source img.jpg`\n",
        "- Video: `python classify/predict.py --weights yolov5s-cls.pt --source vid.mp4`\n",
        "- Directory: `python classify/predict.py --weights yolov5s-cls.pt --source path/`\n",
        "- Glob: `python classify/predict.py --weights yolov5s-cls.pt --source 'path/*.jpg'`\n",
        "- YouTube: `python classify/predict.py --weights yolov5s-cls.pt --source 'https://youtu.be/Zgi9g1ksQHc'`\n",
        "- RTSP, RTMP, HTTP stream: `python classify/predict.py --weights yolov5s-cls.pt --source 'rtsp://example.com/media.mp4'`"
      ],
      "metadata": {
        "id": "aYlfaHDusN-j"
      }
    }
  ]
}